{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ABIDE Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary files\n",
    "In this step, we import the necessary files for the analysis. We also will reduce the ABIDE  datasets to only include the fields that we are interested in analyzing. \n",
    "We will also create a new csv file that is the cleaned data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "# location of partipcant csv files\n",
    "data_dir = \"./dset\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_path):\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Values to be replaced with NaN\n",
    "        values_to_replace = [-9999.0, \"#\", \"-9999\", \"-9999.0\", \"`\"]\n",
    "\n",
    "        # Replace the specified values with NaN\n",
    "        for value in values_to_replace:\n",
    "            data.replace(value, np.nan, inplace=True)\n",
    "\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file at {file_path} does not exist.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(\"The file is empty.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(\"The file could not be parsed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original abide I and II csv files\n",
    "abide1_df = load_csv(op.join(data_dir, \"new_data_abide1.csv\"))\n",
    "abide2_df = load_csv(op.join(data_dir, \"new_data_abide2.csv\"))\n",
    "\n",
    "# add a column that specifies which version of abide\n",
    "abide1_df[\"ABIDE\"] = 1\n",
    "abide2_df[\"ABIDE\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce abide1 and abide2 with demographics of interest\n",
    "abide1_df = abide1_df[\n",
    "    [\n",
    "        \"ABIDE\",\n",
    "        \"alternative_id_1\",\n",
    "        \"DX_GROUP\",\n",
    "        \"DSM_IV_TR\",\n",
    "        \"AGE_AT_SCAN\",\n",
    "        \"SEX\",\n",
    "        \"HANDEDNESS_CATEGORY\",\n",
    "        \"COMORBIDITY\",\n",
    "        \"CURRENT_MED_STATUS\",\n",
    "        \"ADI_RRB_TOTAL_C\",\n",
    "        \"ADI_R_SOCIAL_TOTAL_A\",\n",
    "        \"ADI_R_VERBAL_TOTAL_BV\",\n",
    "        \"ADI_R_RSRCH_RELIABLE\",\n",
    "        \"ADOS_RSRCH_RELIABLE\",\n",
    "        \"ADOS_GOTHAM_SOCAFFECT\",\n",
    "        \"ADOS_GOTHAM_RRB\",\n",
    "        \"SRS_MOTIVATION\",\n",
    "        \"VINELAND_DAILYLVNG_STANDARD\",\n",
    "        \"VINELAND_COPING_V_SCALED\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "abide2_df = abide2_df[\n",
    "    [\n",
    "        \"ABIDE\",\n",
    "        \"SUB_ID\",\n",
    "        \"DX_GROUP\",\n",
    "        \"PDD_DSM_IV_TR\",\n",
    "        \"AGE_AT_SCAN\",\n",
    "        \"SEX\",\n",
    "        \"HANDEDNESS_CATEGORY\",\n",
    "        \"NONASD_PSYDX_LABEL\",\n",
    "        \"CURRENT_MED_STATUS\",\n",
    "        \"ADI_R_RRB_TOTAL_C\",\n",
    "        \"ADI_R_SOCIAL_TOTAL_A\",\n",
    "        \"ADI_R_VERBAL_TOTAL_BV\",\n",
    "        \"ADI_R_RSRCH_RELIABLE\",\n",
    "        \"ADOS_RSRCH_RELIABLE\",\n",
    "        \"ADOS_2_SOCAFFECT\",\n",
    "        \"ADOS_2_RRB\",\n",
    "        \"SRS_MOTIVATION_RAW\",\n",
    "        \"VINELAND_DAILYLIVING_STANDARD\",\n",
    "        \"VINELAND_COPING_V_SCALED\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "# rename the columns in abide2 to match abide1\n",
    "abide2_df = abide2_df.rename(\n",
    "    columns={\n",
    "        \"SUB_ID\": \"alternative_id_1\",\n",
    "        \"PDD_DSM_IV_TR\": \"DSM_IV_TR\",\n",
    "        \"NONASD_PSYDX_LABEL\": \"COMORBIDITY\",\n",
    "        \"ADI_R_RRB_TOTAL_C\": \"ADI_RRB_TOTAL_C\",\n",
    "        \"ADOS_2_SOCAFFECT\": \"ADOS_GOTHAM_SOCAFFECT\",\n",
    "        \"ADOS_2_RRB\": \"ADOS_GOTHAM_RRB\",\n",
    "        \"SRS_MOTIVATION_RAW\": \"SRS_MOTIVATION\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# combine the two datasets into one\n",
    "abide_df = pd.concat([abide1_df, abide2_df], ignore_index=True)\n",
    "print(abide_df)\n",
    "\n",
    "\n",
    "# change handedness from strings to numerics\n",
    "abide_df[\"HANDEDNESS_CATEGORY\"].replace(\n",
    "    {\"R\": 1, \"L\": 2, \"Ambi\": 3, \"Mixed\": 3, \"L->R\": 3}, inplace=True\n",
    ")\n",
    "\n",
    "abide_df[\"CURRENT_MED_STATUS\"].replace(\n",
    "    {\"0\": 0, \"1\": 1, \"0.0\": 0, \"1.0\": 1, \"'\": np.nan}, inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save the melted DataFrame to the CSV file\n",
    "'''csv_file_path = op.join(data_dir, \"abide.csv\")\n",
    "abide_df.to_csv(csv_file_path, index=False)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Count Values\n",
    "Here we find the counts of how many participants fall into various categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of participants in each of the diagnosis categories\n",
    "# 1 = ASD; 2 = TD\n",
    "print(abide_df[\"CURRENT_MED_STATUS\"].unique())\n",
    "# to find the total count for combined ASD and HC\n",
    "totcolumn_count = [\"DX_GROUP\", \"DSM_IV_TR\"]\n",
    "for column in totcolumn_count:\n",
    "    count = abide_df[column].value_counts(dropna=False)\n",
    "    print(count)\n",
    "\n",
    "# Loop through the list of column combinations and count values\n",
    "dxcolumn_count = [\n",
    "    [\"DX_GROUP\", \"SEX\"],\n",
    "    [\"DX_GROUP\", \"HANDEDNESS_CATEGORY\"],\n",
    "    [\"DX_GROUP\", \"CURRENT_MED_STATUS\"],\n",
    "    [\"DX_GROUP\", \"ADI_R_RSRCH_RELIABLE\"],\n",
    "    [\"DX_GROUP\", \"ADOS_RSRCH_RELIABLE\"],\n",
    "]\n",
    "for columns in dxcolumn_count:\n",
    "    count = abide_df[columns].value_counts(dropna=False).reset_index()\n",
    "    print(count)\n",
    "\n",
    "# Counting NaN values in all columns\n",
    "nan_count1 = abide_df[abide_df[\"DX_GROUP\"] == 1].isna().sum()\n",
    "nan_count2 = abide_df[abide_df[\"DX_GROUP\"] == 2].isna().sum()\n",
    "\n",
    "print(\"Nan Count ASD:\", nan_count1, \"NaN Count HC:\", nan_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating statistcal values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are creating a df that will be used to run statistical tests in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just calling the abide df that we are going to manipulate\n",
    "df = pd.read_csv(op.join(csv_dir, \"abide.csv\"))\n",
    "print(df)\n",
    "\n",
    "# Reduce abide df\n",
    "stat_df = df[\n",
    "    [\n",
    "        \"alternative_id_1\",\n",
    "        \"DX_GROUP\",\n",
    "        \"DSM_IV_TR\",\n",
    "        \"AGE_AT_SCAN\",\n",
    "        \"SEX\",\n",
    "        \"HANDEDNESS_CATEGORY\",\n",
    "        \"COMORBIDITY\",\n",
    "        \"CURRENT_MED_STATUS\",\n",
    "        \"ADI_RRB_TOTAL_C\",\n",
    "        \"ADI_R_SOCIAL_TOTAL_A\",\n",
    "        \"ADI_R_VERBAL_TOTAL_BV\",\n",
    "        \"ADI_R_RSRCH_RELIABLE\",\n",
    "        \"ADOS_RSRCH_RELIABLE\",\n",
    "        \"ADOS_GOTHAM_SOCAFFECT\",\n",
    "        \"ADOS_GOTHAM_RRB\",\n",
    "        \"SRS_MOTIVATION\",\n",
    "        \"VINELAND_DAILYLVNG_STANDARD\",\n",
    "        \"VINELAND_COPING_V_SCALED\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore this part for now, I attempted to do the tests in python and they didn't workout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this for now\n",
    "#abide 1\n",
    "# Extract ages for DX_GROUP 1 (ASD) and DX_GROUP 2 (TD) into arrays\n",
    "asd_ages = abide1_df[abide_df[\"DX_GROUP\"] == 1][\"AGE_AT_SCAN\"].to_numpy(dtype=float)\n",
    "td_ages = abide1_df[abide_df[\"DX_GROUP\"] == 2][\"AGE_AT_SCAN\"].to_numpy(dtype=float)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_val = ttest_ind(asd_ages, td_ages)\n",
    "\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_val)\n",
    "\n",
    "#abide 2\n",
    "# Extract ages for DX_GROUP 1 (ASD) and DX_GROUP 2 (TD) into arrays\n",
    "asd_ages = abide2_df[abide_df[\"DX_GROUP\"] == 1][\"AGE_AT_SCAN\"].to_numpy(dtype=float)\n",
    "td_ages = abide2_df[abide_df[\"DX_GROUP\"] == 2][\"AGE_AT_SCAN\"].to_numpy(dtype=float)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_val = ttest_ind(asd_ages, td_ages)\n",
    "\n",
    "print('t-statistic:', t_stat)\n",
    "print('p-value:', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find some statistics to describe the counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxcolumn_dist = [\n",
    "    [\"DX_GROUP\", \"AGE_AT_SCAN\"],\n",
    "    [\"DX_GROUP\", \"ADI_RRB_TOTAL_C\"],\n",
    "    [\"DX_GROUP\", \"ADI_R_SOCIAL_TOTAL_A\"],\n",
    "    [\"DX_GROUP\", \"ADI_R_VERBAL_TOTAL_BV\"],\n",
    "    [\"DX_GROUP\", \"ADOS_GOTHAM_SOCAFFECT\"],\n",
    "    [\"DX_GROUP\", \"ADOS_GOTHAM_RRB\"],\n",
    "    [\"DX_GROUP\", \"SRS_MOTIVATION\"],\n",
    "    [\"DX_GROUP\", \"VINELAND_DAILYLVNG_STANDARD\"],\n",
    "    [\"DX_GROUP\", \"VINELAND_COPING_V_SCALED\"],\n",
    "    [\"DX_GROUP\", \"VINELAND_DAILYLIVING_STANDARD\"],\n",
    "]\n",
    "\n",
    "for columns in dxcolumn_dist:\n",
    "    filtered_df = abide_df[abide_df[\"DX_GROUP\"] == 1]\n",
    "    describe = filtered_df[columns[1]].describe()\n",
    "    print(f\"ASD ({columns[1]}):\")\n",
    "    print(describe)\n",
    "\n",
    "    filtered_df = abide_df[abide_df[\"DX_GROUP\"] == 2]\n",
    "    describe = filtered_df[columns[1]].describe()\n",
    "    print(f\"TD ({columns[1]}):\")\n",
    "    print(describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Comorbidites\n",
    "In this bit of code, we create a new csv file that counts how many times a comorbidity is listed for ASD/TD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of DX_GROUP values to iterate through\n",
    "dx_group_values = [1, 2]\n",
    "\n",
    "# create an empty dataframe\n",
    "comorb_df = pd.DataFrame(columns=[\"COMORBIDITY\"])\n",
    "\n",
    "# Loop through each DX_GROUP\n",
    "# this will add two columns for ASD, TD comorbidity counts\n",
    "for dx_group in dx_group_values:\n",
    "    # list the all possible comorbidities\n",
    "    comorb = abide_df[abide_df[\"DX_GROUP\"] == dx_group][\"COMORBIDITY\"].unique()\n",
    "    # count the number of occurences\n",
    "    comorb_count = abide_df[abide_df[\"DX_GROUP\"] == dx_group][\n",
    "        \"COMORBIDITY\"\n",
    "    ].value_counts()\n",
    "    print(comorb_count)\n",
    "    # create the column names\n",
    "    column_name = f\"Count ASD\" if dx_group == 1 else f\"Count TD\"\n",
    "    comorb_df_group = pd.DataFrame(comorb_count.reset_index())\n",
    "    comorb_df_group.columns = [\"COMORBIDITY\", column_name]\n",
    "\n",
    "    # merge new columns with empty df\n",
    "    if comorb_df.empty:\n",
    "        comorb_df = comorb_df_group\n",
    "    else:\n",
    "        comorb_df = comorb_df.merge(comorb_df_group, on=\"COMORBIDITY\", how=\"outer\")\n",
    "\n",
    "comorb_df.loc[\"Total Counts\"] = comorb_df.sum(numeric_only=True, axis=0, skipna=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "csv_file_path = op.join(csv_dir, \"abide_comorb.csv\")\n",
    "comorb_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a csv of seperated comorbidities and then simplified them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# List of DX_GROUP values to iterate through\n",
    "dx_group_values = [1, 2]\n",
    "\n",
    "# Create an empty DataFrame with columns for COMORBIDITY, Count ASD, and Count TD\n",
    "comorb_df = pd.DataFrame(columns=[\"COMORBIDITY\"])\n",
    "\n",
    "\n",
    "# Regular expression pattern for matching variations of \"ADHD\"\n",
    "adhd_pattern = re.compile(r\"ADHD\", re.IGNORECASE)\n",
    "# Regular expression pattern for matching variations of \"MDD\"\n",
    "mdd_pattern = re.compile(r\"MDD\", re.IGNORECASE)\n",
    "\n",
    "# Loop through each DX_GROUP value\n",
    "for dx_group in dx_group_values:\n",
    "    # Filter the DataFrame for the current DX_GROUP value\n",
    "    comorb_array = abide_df[abide_df[\"DX_GROUP\"] == dx_group][\"COMORBIDITY\"].unique()\n",
    "    comorb_list = comorb_array.tolist()\n",
    "    comorb_split = []\n",
    "    for item in comorb_list:\n",
    "        if isinstance(item, str):\n",
    "            comorb_split.extend(item.split(\";\"))\n",
    "\n",
    "    # Remove leading and trailing spaces from each item in the list\n",
    "    comorb_split = [value.strip() for value in comorb_split]\n",
    "\n",
    "    # Create a dictionary to map keywords to specific values\n",
    "    keyword_mapping = {\n",
    "        \"anxiety\": \"Anxiety\",\n",
    "        \"phobia\": \"Phobia\",\n",
    "        \"tic\": \"Tic Disorder\",\n",
    "        \"dysth\": \"Dysthymia\",\n",
    "        \"enuresis\": \"Enuresis\",\n",
    "        \"depr\": \"Depression\",\n",
    "        \"MDD\": \"Depression\",\n",
    "        \"adhd\": \"ADHD\",\n",
    "        \"bipolar\": \"Bipolar Disorder\",\n",
    "        \"encopresis\": \"Encopresis\",\n",
    "        \"schizo\": \"Schizophrenic Disorder\",\n",
    "        \"GAD\": \"GAD\",\n",
    "        \"mood\": \"Mood Disorder\",\n",
    "        \"learn\": \"Nonverbal Learning Disorder\",\n",
    "        \"dyslexia\": \"Developmental Dyslexia\",\n",
    "        \"tourettes\": \"Tourettes Disorder\",\n",
    "        \"disrupt\": \"Disruptive Disorder\",\n",
    "        \"sensory\": \"Sensory Integration Disorder\",\n",
    "        \"ODD\": \"ODD\",\n",
    "        \"PTSD\": \"PTSD\",\n",
    "    }\n",
    "\n",
    "    # Replace keywords with their corresponding values using case-insensitive search\n",
    "    for i, value in enumerate(comorb_split):\n",
    "        for keyword, mapped_value in keyword_mapping.items():\n",
    "            if re.search(keyword, value, re.IGNORECASE):\n",
    "                comorb_split[i] = mapped_value\n",
    "\n",
    "    # Filter out comorbidities that are not in the keyword mapping\n",
    "    comorb_split = [\n",
    "        value for value in comorb_split if value in keyword_mapping.values()\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with a named column\n",
    "    comorb_splitdf = pd.DataFrame(comorb_split, columns=[\"COMORBIDITY\"])\n",
    "\n",
    "    # Count unique values and add them to the comorb_df\n",
    "    comorb_count = comorb_splitdf[\"COMORBIDITY\"].value_counts()\n",
    "\n",
    "    column_name = f\"Count ASD\" if dx_group == 1 else f\"Count TD\"\n",
    "    comorb_df_group = pd.DataFrame(comorb_count.reset_index())\n",
    "\n",
    "    comorb_df_group.columns = [\"COMORBIDITY\", column_name]\n",
    "\n",
    "    # merge new columns with the empty DataFrame\n",
    "    if comorb_df.empty:\n",
    "        comorb_df = comorb_df_group\n",
    "    else:\n",
    "        comorb_df = comorb_df.merge(comorb_df_group, on=\"COMORBIDITY\", how=\"outer\")\n",
    "\n",
    "    comorb_df.loc[\"Total Counts\"] = comorb_df.sum(\n",
    "        numeric_only=True, axis=0, skipna=True\n",
    "    )\n",
    "\n",
    "\n",
    "comorb_df = comorb_df.drop(19)\n",
    "print(comorb_df)\n",
    "# Save DataFrame to the CSV file\n",
    "'''csv_file_path = op.join(data_dir, \"abide_comorb_cleaned.csv\")\n",
    "comorb_df.to_csv(csv_file_path, index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define replacement lists\n",
    "adhd = [\n",
    "    \"ADHD\",\n",
    "    \"Tic Disorder\",\n",
    "    \"Nonverbal Learning Disorder\",\n",
    "    \"Developmental Dyslexia\",\n",
    "    \"Tourettes Disorder\",\n",
    "    \"Sensory Integration Disorder\",\n",
    "]\n",
    "anxiety = [\"Phobia\", \"GAD\", \"Anxiety\", \"PTSD\"]\n",
    "mood = [\"Dysthymia\", \"Depression\", \"Mood Disorder\"]\n",
    "disrupt = [\"ODD\", \"Disruptive Disorder\"]\n",
    "remove = [\"Enuresis\", \"Encopresis\", \"Bipolar Disorder\", \"Schizophrenic Disorder\"]\n",
    "\n",
    "# Define replacement dictionary\n",
    "replacements = {\n",
    "    \"ADHD\": \"ADHD/Other ND\",\n",
    "    \"Tic Disorder\": \"ADHD/Other ND\",\n",
    "    \"Nonverbal Learning Disorder\": \"ADHD/Other ND\",\n",
    "    \"Developmental Dyslexia\": \"ADHD/Other ND\",\n",
    "    \"Tourettes Disorder\": \"ADHD/Other ND\",\n",
    "    \"Sensory Integration Disorder\": \"ADHD/Other ND\",\n",
    "    \"Phobia\": \"Anxiety\",\n",
    "    \"GAD\": \"Anxiety\",\n",
    "    \"Anxiety\": \"Anxiety\",\n",
    "    \"PTSD\": \"Anxiety\",\n",
    "    \"Dysthymia\": \"Mood Disorder\",\n",
    "    \"Depression\": \"Mood Disorder\",\n",
    "    \"Mood Disorder\": \"Mood Disorder\",\n",
    "    \"ODD\": \"Disruptive\",\n",
    "    \"Disruptive Disorder\": \"Disruptive\",\n",
    "    \"Enuresis\": None,\n",
    "    \"Encopresis\": None,\n",
    "    \"Bipolar Disorder\": None,\n",
    "    \"Schizophrenic Disorder\": None,\n",
    "}\n",
    "\n",
    "# Replace values in the 'COMORBIDITY' column based on the dictionary\n",
    "comorb_df[\"COMORBIDITY\"].replace(replacements, inplace=True)\n",
    "\n",
    "# Drop rows where 'COMORBIDITY' is None (corresponding to values in the 'remove' list)\n",
    "comorb_df.dropna(subset=[\"COMORBIDITY\"], inplace=True)\n",
    "\n",
    "# Combine counts for the same comorbidity names\n",
    "comorb_clean_combined = (\n",
    "    comorb_df.groupby(\"COMORBIDITY\")\n",
    "    .agg({\"Count ASD\": \"sum\", \"Count TD\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Print the updated DataFrame with combined counts\n",
    "print(comorb_clean_combined)\n",
    "\n",
    "# Save DataFrame to the CSV file\n",
    "'''csv_file_path = op.join(data_dir, \"abide_comorb_simplified.csv\")\n",
    "comorb_clean_combined.to_csv(csv_file_path, index=False)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
