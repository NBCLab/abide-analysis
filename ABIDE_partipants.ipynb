{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./\"\n",
    "data_dir = \"./dset\"\n",
    "group_dir = op.join(data_dir, \"group/habenula\")\n",
    "age_dir = op.join(data_dir, \"age-effect5-21old/habenula\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### collecting df w subject info for 1584 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for whole group\n",
    "subject_df = pd.read_csv(\n",
    "    op.join(group_dir, \"sub-group_task-rest_desc-1S2StTesthabenula_table.txt\"), sep=\"\\t\"\n",
    ")\n",
    "print(subject_df)\n",
    "\n",
    "unique_subjects = subject_df[\"Subj\"].nunique()\n",
    "print(f\"Number of unique subjects: {unique_subjects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# run for just age group\n",
    "subject_df = pd.read_csv(\n",
    "    op.join(age_dir, \"sub-group_task-rest_desc-Agehabenula_table.txt\"), sep=\"\\t\"\n",
    ")\n",
    "print(subject_df)\n",
    "\n",
    "unique_subjects = subject_df[\"Subj\"].nunique()\n",
    "print(f\"Number of unique subjects: {unique_subjects}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_df = pd.read_csv(op.join(data_dir, \"participants.tsv\"), sep=\"\\t\")\n",
    "print(participant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "merged_df = pd.merge(\n",
    "    subject_df, participant_df, left_on=\"Subj\", right_on=\"participant_id\"\n",
    ")\n",
    "merged_df = merged_df.drop(columns=[\"participant_id\"])\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns you want to keep\n",
    "columns_to_keep = [\n",
    "    \"Subj\",\n",
    "    \"DX_GROUP\",\n",
    "    \"DSM_IV_TR\",\n",
    "    \"AGE_AT_SCAN\",\n",
    "    \"SEX\",\n",
    "    \"HANDEDNESS_CATEGORY\",\n",
    "    \"CURRENT_MED_STATUS\",\n",
    "    \"COMORBIDITY\",\n",
    "]\n",
    "\n",
    "# Create a new DataFrame with only the desired columns\n",
    "participant_df = merged_df[columns_to_keep]\n",
    "print(participant_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -9999 and -9999.0 with NaN across the entire DataFrame\n",
    "participant_df.replace([-9999, -9999.0, \"-9999\", \"`\"], np.nan, inplace=True)\n",
    "\n",
    "# change handedness from strings to numerics\n",
    "'''participant_df[\"HANDEDNESS_CATEGORY\"].replace(\n",
    "    {\"R\": 1, \"L\": 2, \"Ambi\": 3, \"Mixed\": 3, \"L->R\": 3}, inplace=True\n",
    ")'''\n",
    "\n",
    "# Replace values in \"HANDEDNESS_CATEGORY\"\n",
    "participant_df[\"HANDEDNESS_CATEGORY\"].replace(\n",
    "    {\n",
    "        \"1\": \"R\",\n",
    "        '1.0': \"R\",\n",
    "        \"2\": \"L\",\n",
    "        \"2.0\": \"L\",\n",
    "        \"Mixed\": \"Ambi\",\n",
    "        \"3\": \"Mixed\",\n",
    "        \"3.0\": \"Mixed\",\n",
    "        \"3\": \"L->R\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "participant_df[\"HANDEDNESS_CATEGORY\"] = (\n",
    "    participant_df[\"HANDEDNESS_CATEGORY\"]\n",
    "    .replace({'1.0': 1, '2.0': 2, '3.0': 3})\n",
    "    .fillna(participant_df[\"HANDEDNESS_CATEGORY\"])\n",
    ")\n",
    "\n",
    "final_options = participant_df[\"HANDEDNESS_CATEGORY\"].unique()\n",
    "print(final_options)\n",
    "\n",
    "participant_df[\"CURRENT_MED_STATUS\"].replace(\n",
    "    {\"0\": 0, \"1\": 1, \"0.0\": 0, \"1.0\": 1, \"'\": np.nan}, inplace=True\n",
    ")\n",
    "participant_df[\"HANDEDNESS_CATEGORY\"].replace(\n",
    "    {\"R\": 1, \"L\": 2, \"Ambi\": 3, \"Mixed\": 3, \"L->R\": 3}, inplace=True\n",
    ")\n",
    "participant_df[\"DX_GROUP\"].replace(\n",
    "    {1: \"ASD\", 2: \"NT\", \"1\": \"ASD\", \"2\": \"NT\"}, inplace=True\n",
    ")\n",
    "# Display the final DataFrame\n",
    "print(participant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 1 with \"R\", 2 with \"L\", and 3 with \"Ambi\"\n",
    "participant_df[\"HANDEDNESS_CATEGORY\"].replace({1: \"R\", 2: \"L\", 3: \"Ambi\"}, inplace=True)\n",
    "participant_df[\"SEX\"].replace({1: \"M\", 2: \"F\"}, inplace=True)\n",
    "participant_df[\"DSM_IV_TR\"].replace(\n",
    "    {0: \"Control\", 1: \"autism\", 2: \"asperg\", 3: \"pdd\"}, inplace=True\n",
    ")\n",
    "participant_df[\"CURRENT_MED_STATUS\"].replace({0: \"no med\", 1: \"med\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to print unique values for\n",
    "columns = [\n",
    "    \"DX_GROUP\",\n",
    "    \"DSM_IV_TR\",\n",
    "    \"SEX\",\n",
    "    \"HANDEDNESS_CATEGORY\",\n",
    "    \"CURRENT_MED_STATUS\",\n",
    "    \"COMORBIDITY\",\n",
    "]\n",
    "\n",
    "# Print unique values for each column\n",
    "for col in columns:\n",
    "    unique_values = participant_df[col].unique()\n",
    "    print(f\"Unique values in '{col}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"ASD\", \"NT\"]\n",
    "\n",
    "# Filter the dataset for the specified groups\n",
    "filtered_df = participant_df[participant_df[\"DX_GROUP\"].isin(groups)]\n",
    "\n",
    "# Calculate median age and standard deviation\n",
    "median_age = filtered_df[\"AGE_AT_SCAN\"].median()\n",
    "std_age = filtered_df[\"AGE_AT_SCAN\"].std()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Median Age for combined groups: {median_age}\")\n",
    "print(f\"Standard Deviation of Age for combined groups: {std_age}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for group in groups:\n",
    "    count = participant_df[participant_df[\"DX_GROUP\"] == group].value_counts(dropna=False)\n",
    "    print(count)\n",
    "    for index, row in participant_df.iterrows():\n",
    "        if row[\"DX_GROUP\"] == group:\n",
    "            subj = row[\"Subj\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Define the groups of interest\n",
    "groups = [\"ASD\", \"NT\"]\n",
    "\n",
    "# Initialize a dictionary to keep track of counts\n",
    "group_counts = {group: 0 for group in groups}\n",
    "\n",
    "# Loop through the participant_df and count the subjects for each group\n",
    "for group in groups:\n",
    "    count = participant_df[participant_df[\"DX_GROUP\"] == group].shape[0]\n",
    "    group_counts[group] = count\n",
    "    print(f\"Group {group}: {count} subjects\")\n",
    "\n",
    "# Extract ages for the two groups\n",
    "asd_ages = participant_df[participant_df[\"DX_GROUP\"] == \"ASD\"][\"AGE_AT_SCAN\"]\n",
    "td_ages = participant_df[participant_df[\"DX_GROUP\"] == \"NT\"][\"AGE_AT_SCAN\"]\n",
    "\n",
    "# Calculate mean and standard deviation for each group\n",
    "asd_mean_age = asd_ages.mean()\n",
    "asd_std_age = asd_ages.std()\n",
    "td_mean_age = td_ages.mean()\n",
    "td_std_age = td_ages.std()\n",
    "\n",
    "# Perform an independent t-test\n",
    "t_stat, p_value = ttest_ind(\n",
    "    asd_ages, td_ages, equal_var=False\n",
    ")  # Use equal_var=False if variances are unequal\n",
    "\n",
    "# Print mean age and standard deviation for each group\n",
    "print(f\"\\nMean Age:\")\n",
    "print(f\"  Group asd: {asd_mean_age:.2f}\")\n",
    "print(f\"  Group td: {td_mean_age:.2f}\")\n",
    "\n",
    "print(f\"\\nStandard Deviation Age:\")\n",
    "print(f\"  Group asd: {asd_std_age:.2f}\")\n",
    "print(f\"  Group td: {td_std_age:.2f}\")\n",
    "\n",
    "# Print the t-statistic and p-value\n",
    "print(f\"\\nIndependent t-test results:\")\n",
    "print(f\"  t-statistic: {t_stat:.2f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chi-sq tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "# Define the groups for counting\n",
    "groups = participant_df[\"DX_GROUP\"].unique()\n",
    "\n",
    "# List of columns to perform chi-square tests on\n",
    "columns = [\n",
    "    \"DSM_IV_TR\",\n",
    "    \"SEX\",\n",
    "    \"HANDEDNESS_CATEGORY\",\n",
    "    \"CURRENT_MED_STATUS\",\n",
    "]\n",
    "\n",
    "for col in columns:\n",
    "    print(f\"Column: {col}\")\n",
    "\n",
    "    # Create a contingency table for the chi-square test\n",
    "    contingency_table = pd.crosstab(participant_df[\"DX_GROUP\"], participant_df[col])\n",
    "\n",
    "    # Perform the chi-square test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Contingency Table:\")\n",
    "    print(contingency_table)\n",
    "    print(f\"Chi-square statistic: {chi2}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "    print(f\"Degrees of freedom: {dof}\")\n",
    "    print(\"Expected frequencies:\")\n",
    "    print(expected)\n",
    "    print(\"-\" * 40)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Comorbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# List of DX_GROUP values to iterate through\n",
    "dx_group_values = [\"ASD\", \"NT\"]\n",
    "\n",
    "# Create an empty DataFrame with columns for COMORBIDITY, Count ASD, and Count TD\n",
    "comorb_df = pd.DataFrame(columns=[\"COMORBIDITY\"])\n",
    "\n",
    "\n",
    "# Regular expression pattern for matching variations of \"ADHD\"\n",
    "adhd_pattern = re.compile(r\"ADHD\", re.IGNORECASE)\n",
    "# Regular expression pattern for matching variations of \"MDD\"\n",
    "mdd_pattern = re.compile(r\"MDD\", re.IGNORECASE)\n",
    "\n",
    "# Loop through each DX_GROUP value\n",
    "for dx_group in dx_group_values:\n",
    "    # Filter the DataFrame for the current DX_GROUP value\n",
    "    comorb_array = participant_df[participant_df[\"DX_GROUP\"] == dx_group][\"COMORBIDITY\"].unique()\n",
    "    comorb_list = comorb_array.tolist()\n",
    "    comorb_split = []\n",
    "    for item in comorb_list:\n",
    "        if isinstance(item, str):\n",
    "            comorb_split.extend(item.split(\";\"))\n",
    "\n",
    "    # Remove leading and trailing spaces from each item in the list\n",
    "    comorb_split = [value.strip() for value in comorb_split]\n",
    "\n",
    "    # Create a dictionary to map keywords to specific values\n",
    "    keyword_mapping = {\n",
    "        \"anxiety\": \"Anxiety\",\n",
    "        \"phobia\": \"Phobia\",\n",
    "        \"tic\": \"Tic Disorder\",\n",
    "        \"dysth\": \"Dysthymia\",\n",
    "        \"enuresis\": \"Enuresis\",\n",
    "        \"depr\": \"Depression\",\n",
    "        \"MDD\": \"Depression\",\n",
    "        \"adhd\": \"ADHD\",\n",
    "        \"bipolar\": \"Bipolar Disorder\",\n",
    "        \"encopresis\": \"Encopresis\",\n",
    "        \"schizo\": \"Schizophrenic Disorder\",\n",
    "        \"GAD\": \"GAD\",\n",
    "        \"mood\": \"Mood Disorder\",\n",
    "        \"learn\": \"Nonverbal Learning Disorder\",\n",
    "        \"dyslexia\": \"Developmental Dyslexia\",\n",
    "        \"tourettes\": \"Tourettes Disorder\",\n",
    "        \"disrupt\": \"Disruptive Disorder\",\n",
    "        \"sensory\": \"Sensory Integration Disorder\",\n",
    "        \"ODD\": \"ODD\",\n",
    "        \"PTSD\": \"PTSD\",\n",
    "    }\n",
    "\n",
    "    # Replace keywords with their corresponding values using case-insensitive search\n",
    "    for i, value in enumerate(comorb_split):\n",
    "        for keyword, mapped_value in keyword_mapping.items():\n",
    "            if re.search(keyword, value, re.IGNORECASE):\n",
    "                comorb_split[i] = mapped_value\n",
    "\n",
    "    # Filter out comorbidities that are not in the keyword mapping\n",
    "    comorb_split = [\n",
    "        value for value in comorb_split if value in keyword_mapping.values()\n",
    "    ]\n",
    "\n",
    "    # Create a DataFrame with a named column\n",
    "    comorb_splitdf = pd.DataFrame(comorb_split, columns=[\"COMORBIDITY\"])\n",
    "\n",
    "    # Count unique values and add them to the comorb_df\n",
    "    comorb_count = comorb_splitdf[\"COMORBIDITY\"].value_counts()\n",
    "\n",
    "    column_name = f\"Count ASD\" if dx_group == \"ASD\" else f\"Count NT\"\n",
    "    comorb_df_group = pd.DataFrame(comorb_count.reset_index())\n",
    "\n",
    "    comorb_df_group.columns = [\"COMORBIDITY\", column_name]\n",
    "\n",
    "    # merge new columns with the empty DataFrame\n",
    "    if comorb_df.empty:\n",
    "        comorb_df = comorb_df_group\n",
    "    else:\n",
    "        comorb_df = comorb_df.merge(comorb_df_group, on=\"COMORBIDITY\", how=\"outer\")\n",
    "\n",
    "    comorb_df.loc[\"Total Counts\"] = comorb_df.sum(\n",
    "        numeric_only=True, axis=0, skipna=True\n",
    "    )\n",
    "\n",
    "\n",
    "comorb_df = comorb_df\n",
    "print(comorb_df)\n",
    "# Save DataFrame to the CSV file\n",
    "\"\"\"csv_file_path = op.join(data_dir, \"abide_comorb_cleaned.csv\")\n",
    "comorb_df.to_csv(csv_file_path, index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define replacement lists\n",
    "adhd = [\n",
    "    \"ADHD\",\n",
    "    \"Tic Disorder\",\n",
    "    \"Nonverbal Learning Disorder\",\n",
    "    \"Developmental Dyslexia\",\n",
    "    \"Tourettes Disorder\",\n",
    "    \"Sensory Integration Disorder\",\n",
    "]\n",
    "anxiety = [\"Phobia\", \"GAD\", \"Anxiety\", \"PTSD\"]\n",
    "mood = [\"Dysthymia\", \"Depression\", \"Mood Disorder\"]\n",
    "disrupt = [\"ODD\", \"Disruptive Disorder\"]\n",
    "remove = [\"Enuresis\", \"Encopresis\", \"Bipolar Disorder\", \"Schizophrenic Disorder\"]\n",
    "\n",
    "# Define replacement dictionary\n",
    "replacements = {\n",
    "    \"ADHD\": \"ADHD/Other ND\",\n",
    "    \"Tic Disorder\": \"ADHD/Other ND\",\n",
    "    \"Nonverbal Learning Disorder\": \"ADHD/Other ND\",\n",
    "    \"Developmental Dyslexia\": \"ADHD/Other ND\",\n",
    "    \"Tourettes Disorder\": \"ADHD/Other ND\",\n",
    "    \"Sensory Integration Disorder\": \"ADHD/Other ND\",\n",
    "    \"Phobia\": \"Anxiety\",\n",
    "    \"GAD\": \"Anxiety\",\n",
    "    \"Anxiety\": \"Anxiety\",\n",
    "    \"PTSD\": \"Anxiety\",\n",
    "    \"Dysthymia\": \"Mood Disorder\",\n",
    "    \"Depression\": \"Mood Disorder\",\n",
    "    \"Mood Disorder\": \"Mood Disorder\",\n",
    "    \"ODD\": \"Disruptive\",\n",
    "    \"Disruptive Disorder\": \"Disruptive\",\n",
    "    \"Enuresis\": None,\n",
    "    \"Encopresis\": None,\n",
    "    \"Bipolar Disorder\": None,\n",
    "    \"Schizophrenic Disorder\": None,\n",
    "}\n",
    "\n",
    "# Replace values in the 'COMORBIDITY' column based on the dictionary\n",
    "comorb_df[\"COMORBIDITY\"].replace(replacements, inplace=True)\n",
    "\n",
    "# Drop rows where 'COMORBIDITY' is None (corresponding to values in the 'remove' list)\n",
    "comorb_df.dropna(subset=[\"COMORBIDITY\"], inplace=True)\n",
    "\n",
    "# Combine counts for the same comorbidity names\n",
    "comorb_clean_combined = (\n",
    "    comorb_df.groupby(\"COMORBIDITY\")\n",
    "    .agg({\"Count ASD\": \"sum\", \"Count NT\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Print the updated DataFrame with combined counts\n",
    "print(comorb_clean_combined)\n",
    "\n",
    "# Save DataFrame to the CSV file\n",
    "\"\"\"csv_file_path = op.join(data_dir, \"abide_comorb_simplified.csv\")\n",
    "comorb_clean_combined.to_csv(csv_file_path, index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create the contingency table\n",
    "contingency_table = pd.DataFrame(\n",
    "    {\"ASD\": comorb_clean_combined[\"Count ASD\"], \"NT\": comorb_clean_combined[\"Count NT\"]}\n",
    ").T  # Transpose to match the expected format\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "print(f\"Chi-square statistic: {chi2}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(\"Expected frequencies:\")\n",
    "print(expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
