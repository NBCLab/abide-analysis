{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from neuromaps import transforms\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pandas as pd\n",
    "from gradec.utils import _zero_medial_wall\n",
    "import nibabel as nib\n",
    "from nilearn.plotting.cm import _cmap_d as nilearn_cmaps\n",
    "from surfplot import Plot\n",
    "from nilearn import datasets\n",
    "from gradec.plot import plot_radar, plot_cloud\n",
    "from gradec.fetcher import _fetch_features, _fetch_frequencies, _fetch_classification\n",
    "from gradec.utils import _decoding_filter\n",
    "from nimare.decode.continuous import CorrelationDecoder\n",
    "import numpy as np\n",
    "from nilearn.maskers import NiftiMasker\n",
    "from nilearn.image import threshold_img, index_img\n",
    "from neuromaps.datasets import fetch_fslr\n",
    "from nimare.transforms import p_to_z\n",
    "from nilearn.plotting import plot_stat_map\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import nilearn.reporting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from nilearn import datasets, plotting, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = nilearn_cmaps[\"cold_hot\"]\n",
    "CMAP = \"Spectral_r\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of colors in the colormap\n",
    "num_colors = 256\n",
    "\n",
    "# Define anchor points for key colors emphasizing red and blue\n",
    "colors = [\n",
    "    (0.0, 0.0, 0.2),  # Purple\n",
    "    (0.0, 0.0, 0.3),  # Purple\n",
    "    (0.0, 0.0, 0.6),  # Purple\n",
    "    (0.1, 0.0, 0.9),  # Cyan\n",
    "    (0.1, 0.3, 0.9),  # Cyan\n",
    "    (0.1, 0.8, 0.9),  # Cyan\n",
    "    (0.9, 0.7, 0.3),  # Yellow (adjusted)\n",
    "    (1.0, 0.5, 0.2),  # Orange\n",
    "    (1.0, 0.4, 0.2),  # Orange\n",
    "    (1.0, 0.0, 0.3),  # Red\n",
    "    (1.0, 0.0, 0.3),  # Red\n",
    "]  #\n",
    "# Create a smooth interpolation for the custom colormap\n",
    "CMAP = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=num_colors)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.imshow([list(range(256))], aspect=\"auto\", cmap=CMAP)\n",
    "plt.gca().set_visible(False)\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of colors in the colormap\n",
    "num_colors = 256\n",
    "\n",
    "# Define anchor points for key colors emphasizing red and blue\n",
    "colors = [\n",
    "    (0.0, 0.0, 0.2),  # Purple\n",
    "    (0.0, 0.0, 0.6),  # Purple\n",
    "    (0.2, 0.4, 0.9),  # Cyan\n",
    "    (0.9, 0.7, 0.3),  # Yellow (adjusted)\n",
    "    (1.0, 0.5, 0.2),  # Orange\n",
    "    (1.0, 0.4, 0.2),  # Orange\n",
    "    (1.0, 0.0, 0.3),  # Red\n",
    "    (1.0, 0.0, 0.3),  # Red\n",
    "]  #\n",
    "# Create a smooth interpolation for the custom colormap\n",
    "cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=num_colors)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.imshow([list(range(256))], aspect=\"auto\", cmap=cmap)\n",
    "plt.gca().set_visible(False)\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of colors in the colormap\n",
    "num_colors = 256\n",
    "\n",
    "# Define anchor points for key colors emphasizing red and blue\n",
    "colors = [\n",
    "    (0.0, 0.0, 0.2),  # Purple\n",
    "    (0.1, 0.0, 0.9),  # Cyan\n",
    "    (0.1, 0.3, 0.9),  # Cyan\n",
    "    (0.1, 0.8, 0.9),  # Cyan\n",
    "    (0.9, 0.7, 0.4),  # Yellow (adjusted)\n",
    "    (0.9, 0.7, 0.3),  # Yellow (adjusted)\n",
    "    (1.0, 0.5, 0.2),  # Orange\n",
    "    (1.0, 0.4, 0.2),  # Orange\n",
    "    (1.0, 0.0, 0.3),  # Red\n",
    "    (1.0, 0.0, 0.3),  # Red\n",
    "]  #\n",
    "# Create a smooth interpolation for the custom colormap\n",
    "CMAP2 = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=num_colors)\n",
    "\n",
    "plt.figure(figsize=(8, 2))\n",
    "plt.imshow([list(range(256))], aspect=\"auto\", cmap=CMAP2)\n",
    "plt.gca().set_visible(False)\n",
    "plt.colorbar(orientation=\"horizontal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_image(img=None, tol=1, fix=True):\n",
    "    if fix:\n",
    "        mask = img != tol\n",
    "    else:\n",
    "        mask = img <= tol\n",
    "    if img.ndim == 3:\n",
    "        mask = mask.any(2)\n",
    "    mask0, mask1 = mask.any(0), mask.any(1)\n",
    "    return img[np.ix_(mask1, mask0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stat(nii_img_thr, threshold, mask_contours=None, vmax=8, alpha=1, cmap=CMAP):\n",
    "    # Fetch the MNI152 template at higher resolution\n",
    "    template = datasets.load_mni152_template(resolution=0.5)\n",
    "\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plotting.plot_stat_map(\n",
    "        nii_img_thr,\n",
    "        bg_img=template,\n",
    "        black_bg=False,\n",
    "        draw_cross=False,\n",
    "        annotate=True,\n",
    "        alpha=alpha,\n",
    "        cmap=cmap,\n",
    "        threshold=threshold,\n",
    "        cut_coords=[1, 1, -28],\n",
    "        vmax=vmax\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vol(nii_img_thr, threshold, mask_contours=None, vmax=6, alpha=1, cmap=CMAP):\n",
    "    template = datasets.load_mni152_template(resolution=1)\n",
    "\n",
    "    display_modes = [\"x\", \"y\", \"z\"]\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=None, hspace=None)\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "    for dsp_i, display_mode in enumerate(display_modes):\n",
    "        if display_mode == \"z\":\n",
    "            ax = fig.add_subplot(gs[:, 1], aspect=\"equal\")\n",
    "            colorbar = True\n",
    "        else:\n",
    "            ax = fig.add_subplot(gs[dsp_i, 0], aspect=\"equal\")\n",
    "            colorbar = False\n",
    "\n",
    "        display = plot_stat_map(\n",
    "            nii_img_thr,\n",
    "            bg_img=template,\n",
    "            black_bg=False,\n",
    "            draw_cross=False,\n",
    "            annotate=True,\n",
    "            alpha=alpha,\n",
    "            cmap=cmap,\n",
    "            threshold=threshold,\n",
    "            colorbar=colorbar,\n",
    "            display_mode=display_mode,\n",
    "            cut_coords=1,\n",
    "            vmax=vmax,\n",
    "            axes=ax,\n",
    "        )\n",
    "        if mask_contours:\n",
    "            display.add_contours(mask_contours, levels=[0.5], colors=\"black\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surf(nii_img_thr, mask_contours=None, vmax=8, cmap=cmap):\n",
    "    map_lh, map_rh = transforms.mni152_to_fslr(nii_img_thr, fslr_density=\"32k\")\n",
    "    map_lh, map_rh = _zero_medial_wall(\n",
    "        map_lh,\n",
    "        map_rh,\n",
    "        space=\"fsLR\",\n",
    "        density=\"32k\",\n",
    "    )\n",
    "    # midthickness\n",
    "\n",
    "    surfaces = fetch_fslr(density=\"32k\")\n",
    "    lh, rh = surfaces[\"inflated\"]\n",
    "    sulc_lh, sulc_rh = surfaces[\"sulc\"]\n",
    "\n",
    "    p = Plot(surf_lh=lh, surf_rh=rh, layout=\"grid\")\n",
    "    p.add_layer({\"left\": sulc_lh, \"right\": sulc_rh}, cmap=\"binary_r\", cbar=False)\n",
    "    p.add_layer(\n",
    "        {\"left\": map_lh, \"right\": map_rh},\n",
    "        cmap=cmap,\n",
    "        cbar=False,\n",
    "        color_range=(-vmax, vmax)\n",
    "    )\n",
    "    if mask_contours:\n",
    "        mask_lh, mask_rh = transforms.mni152_to_fslr(mask_contours, fslr_density=\"32k\")\n",
    "        mask_lh, mask_rh = _zero_medial_wall(\n",
    "            mask_lh,\n",
    "            mask_rh,\n",
    "            space=\"fsLR\",\n",
    "            density=\"32k\",\n",
    "        )\n",
    "        mask_arr_lh = mask_lh.agg_data()\n",
    "        mask_arr_rh = mask_rh.agg_data()\n",
    "        countours_lh = np.zeros_like(mask_arr_lh)\n",
    "        countours_lh[mask_arr_lh != 0] = 1\n",
    "        countours_rh = np.zeros_like(mask_arr_rh)\n",
    "        countours_rh[mask_arr_rh != 0] = 1\n",
    "\n",
    "        colors = [(0, 0, 0, 0)]\n",
    "        contour_cmap = ListedColormap(colors, 'regions', N=1)\n",
    "        line_cmap = ListedColormap([\"black\"], 'regions', N=1)\n",
    "        p.add_layer(\n",
    "            {\"left\": countours_lh, \"right\": countours_rh}, \n",
    "            cmap=line_cmap, \n",
    "            as_outline=True, \n",
    "            cbar=False\n",
    "        )\n",
    "        p.add_layer(\n",
    "            {\"left\": countours_lh, \"right\": countours_rh},\n",
    "            cmap=contour_cmap,\n",
    "            cbar=False,\n",
    "        )\n",
    "    \n",
    "    return p.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MED = False\n",
    "data_dir = op.join(\"./dset\")\n",
    "abide_dir = op.join(data_dir, \"group-medication/habenula\") if MED else op.join(data_dir, \"group/habenula\")\n",
    "fig_dir = op.join(abide_dir, \"fig\")\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSET, MODEL = \"neuroquery\", \"lda\"\n",
    "decoding_dir = \"./decoding\"\n",
    "decoder_fn = op.join(decoding_dir, f\"{MODEL}_{DSET}_decoder.pkl.gz\")\n",
    "\n",
    "decoder = CorrelationDecoder.load(decoder_fn)\n",
    "\n",
    "features = _fetch_features(DSET, MODEL, data_dir=decoding_dir)\n",
    "frequencies = _fetch_frequencies(DSET, MODEL, data_dir=decoding_dir)\n",
    "classification, class_lst = _fetch_classification(DSET, MODEL, data_dir=decoding_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = datasets.load_mni152_brain_mask(resolution=1)\n",
    "masker = NiftiMasker(mask_img=mask_img)\n",
    "masker = masker.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {\n",
    "    \"1s\": \"Group Average (One-Sample T-Test)\",\n",
    "    \"2s\": \"Group Comparison (Two-Sample Unpaired T-Test: ASD-TD)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brik_fn = op.join(abide_dir, \"sub-group_task-rest_desc-1S2StTesthabenula_briks+tlrc.BRIK\")\n",
    "table_fn = op.join(abide_dir, \"sub-group_task-rest_desc-1S2StTesthabenula_table.txt\")\n",
    "nii_1s_fn = op.join(abide_dir, \"sub-group_task-rest_desc-1SampletTest_zmap.nii.gz\")\n",
    "nii_2s_fn = op.join(abide_dir, \"sub-group_task-rest_desc-2SampletTest_zmap.nii.gz\")\n",
    "cluster_fn = op.join(data_dir, \"group-medication\", \"habenula\", \"clustsim\", \"clustsim_out.NN2_2sided.1D\")\n",
    "\n",
    "column_names = [\".10000\", \".05000\", \".02000\", \".01000\"]\n",
    "cluster_df = pd.read_table(cluster_fn, skiprows=8, delim_whitespace=True, names=column_names)\n",
    "cluster_df = cluster_df.reset_index()\n",
    "cluster_df.rename(columns={'index': 'pthr'}, inplace=True)\n",
    "\n",
    "\n",
    "brik_idx = [9, 11] if MED else [8, 10]\n",
    "nii_fns = [nii_1s_fn, nii_2s_fn]\n",
    "tests = [\"1s\", \"2s\"]\n",
    "alpha = \".02000\"\n",
    "pthrs = [0.0001, 0.0001]\n",
    "cohen_thresh = 0\n",
    "\n",
    "data_df = pd.read_csv(table_fn, sep=\"\\t\")\n",
    "n_sub = data_df.groupby(\"group\").size().sum()\n",
    "n_sub_1, n_sub_2 = data_df.groupby(\"group\").size().values\n",
    "\n",
    "for brik_i, nii_fn, test, pthr in zip(brik_idx, nii_fns, tests, pthrs):\n",
    "    convert = f\"3dAFNItoNIFTI \\\n",
    "        -prefix {nii_fn} \\\n",
    "        {brik_fn}[{brik_i}]\"\n",
    "    print(convert)\n",
    "    os.system(convert)\n",
    "\n",
    "    '''if test == \"1s\":\n",
    "        convert = f\"3dAFNItoNIFTI \\\n",
    "            -prefix {nii_fn} \\\n",
    "            {brik_fn}[{brik_i}]\"\n",
    "        os.system(convert)\n",
    "\n",
    "    elif test == \"2s\":\n",
    "        convert = f\"3dcalc -a {brik_fn}'[{brik_i}]' -expr '-1*a' -prefix {nii_fn}\"\n",
    "        os.system(convert)'''\n",
    "\n",
    "    nii_img = nib.load(nii_fn)\n",
    "    z_thresh = p_to_z(pthr)\n",
    "\n",
    "    clust_ext = cluster_df.loc[cluster_df[\"pthr\"] == pthr, alpha].values[0]\n",
    "    nii_thr_img = threshold_img(nii_img, z_thresh, cluster_threshold=clust_ext)\n",
    "    print(clust_ext, pthr, z_thresh)\n",
    "\n",
    "    nii_arr = masker.transform(nii_img)\n",
    "    if test == \"1s\":\n",
    "        nii_cohen_arr = nii_arr / np.sqrt(n_sub)\n",
    "    elif test == \"2s\":\n",
    "        nii_cohen_arr = nii_arr / (np.sqrt(n_sub_1) + np.sqrt(n_sub_2))\n",
    "\n",
    "    nii_cohen_img = masker.inverse_transform(nii_cohen_arr)\n",
    "\n",
    "    nii_thr_arr = masker.transform(nii_thr_img)\n",
    "    nii_contour_arr = np.zeros_like(nii_thr_arr)\n",
    "    nii_contour_arr[(nii_thr_arr > z_thresh) | (nii_thr_arr < -z_thresh)] = 1\n",
    "    nii_contour_img = masker.inverse_transform(nii_contour_arr)\n",
    "    nii_contour_img_3d = index_img(nii_contour_img, 0)\n",
    "\n",
    "    vmax = round(np.max(np.abs(nii_thr_arr)), 2)\n",
    "    vmax = 13 if vmax > 13 else vmax\n",
    "    # c_vmax = round(np.max(np.abs(nii_cohen_arr)), 2)\n",
    "    c_vmax = 0.1 if test == \"2s\" else 0.3\n",
    "\n",
    "    clusters = nilearn.reporting.get_clusters_table(\n",
    "        nii_thr_img, z_thresh, two_sided=True\n",
    "    )\n",
    "    print(clusters)  # coordinates are same as affine of input (MNI)\n",
    "\n",
    "    nib.save(nii_thr_img, op.join(abide_dir, f\"{test}_thresh_zmap.nii.gz\"))\n",
    "\n",
    "    # stat_fig = plot_vol(nii_thr_img, z_thresh, vmax=vmax)\n",
    "    vol_fig = plot_vol(nii_thr_img, z_thresh, vmax=vmax)\n",
    "    cohen_fig = plot_vol(nii_cohen_img, cohen_thresh, mask_contours=nii_contour_img_3d, vmax=c_vmax, alpha=0.8, cmap=CMAP)\n",
    "\n",
    "    surf_fig = plot_surf(nii_thr_img, vmax=vmax)\n",
    "    cohen_surf_fig = plot_surf(nii_cohen_img, mask_contours=nii_contour_img_3d, vmax=c_vmax, cmap=CMAP)\n",
    "\n",
    "    if test == \"1s\":\n",
    "        nii_pos_arr = np.where(nii_arr > 0, nii_arr, 0)\n",
    "        img_to_decode = masker.inverse_transform(nii_pos_arr)\n",
    "    elif test == \"2s\":\n",
    "        nii_neg_arr = abs(np.where(nii_arr < 0, nii_arr, 0))\n",
    "        img_to_decode = masker.inverse_transform(nii_neg_arr)\n",
    "\n",
    "    corrs_df = decoder.transform(img_to_decode)\n",
    "    num_val = [int(lab.split(\"__\")[1].split(\"_\")[0]) for lab in corrs_df.index.to_list()]\n",
    "    indices = np.argsort(num_val)\n",
    "    corrs_df = corrs_df.iloc[indices]\n",
    "    filtered_df, filtered_features, filtered_frequencies = _decoding_filter(\n",
    "        corrs_df,\n",
    "        features,\n",
    "        classification,\n",
    "        freq_by_topic=frequencies,\n",
    "        class_by_topic=class_lst,\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    corrs = filtered_df[\"r\"].to_numpy()\n",
    "    # Radar plot\n",
    "    '''plot_radar(\n",
    "        corrs, \n",
    "        filtered_features,\n",
    "        MODEL,\n",
    "        cmap=CMAP2,\n",
    "        out_fig=op.join(fig_dir, f\"{test}_radar.png\"),\n",
    "    )\n",
    "\n",
    "    # Word cloud plot\n",
    "    plot_cloud(\n",
    "        corrs, \n",
    "        filtered_features,\n",
    "        MODEL,\n",
    "        width=5,\n",
    "        height=10,\n",
    "        frequencies=filtered_frequencies,\n",
    "        cmap=CMAP2,\n",
    "        out_fig=op.join(fig_dir, f\"{test}_wordcloud.png\"),\n",
    "    )'''\n",
    "    # plt.show(stat_fig)\n",
    "\n",
    "    '''stat_fig.savefig(\n",
    "        op.join(fig_dir, f\"{test}_stat.png\"), bbox_inches=\"tight\", dpi=300\n",
    "    )'''\n",
    "    # vol_fig.savefig(op.join(fig_dir, f\"{test}_volume.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    # cohen_fig.savefig(op.join(fig_dir, f\"{test}_volume-cohen.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    # surf_fig.savefig(op.join(fig_dir, f\"{test}_surface.png\"), bbox_inches=\"tight\", dpi=300)\n",
    "    # cohen_surf_fig.savefig(op.join(fig_dir, f\"{test}_surface-cohen.png\"), bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn.image import threshold_img\n",
    "from nilearn.reporting import get_clusters_table\n",
    "\n",
    "\n",
    "# Function to execute the AFNI whereami command and parse its output\n",
    "def find_region(coord):\n",
    "    # Format the coordinates properly for the whereami command\n",
    "    coord_str = f\"{coord[0]} {coord[1]} {coord[2]}\"\n",
    "    # Command to query AFNI's whereami\n",
    "    whereami_cmd = f\"whereami [{coord_str}] -atlas MNI_Glasser_HCP_v1.0 -classic\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            whereami_cmd,\n",
    "            shell=True,\n",
    "            check=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "        )\n",
    "        output = result.stdout\n",
    "        # Print the full output for debugging purposes\n",
    "        print(f\"whereami output for {coord}:\")\n",
    "        print(output)\n",
    "        # Parse the output to extract the region name\n",
    "        for line in output.split(\"\\n\"):\n",
    "            if \"Focus point (LPI)\" in line:\n",
    "                parts = line.split()\n",
    "                if len(parts) > 3:\n",
    "                    return parts[3]  # Extract the region name\n",
    "        return \"Unknown\"\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\n",
    "            f\"Error running whereami command: {e}\\nOutput: {e.output}\\nError: {e.stderr}\"\n",
    "        )\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Extract the coordinates from the clusters table and map to regions\n",
    "def map_clusters_to_regions(clusters_df):\n",
    "    coordinates = clusters_df[[\"X\", \"Y\", \"Z\"]].values\n",
    "    regions = [find_region(coord) for coord in coordinates]\n",
    "    clusters_df[\"Region\"] = regions\n",
    "    return clusters_df\n",
    "\n",
    "\n",
    "# Iterate over your clusters and map to regions\n",
    "for brik_i, nii_fn, test, pthr in zip(brik_idx, nii_fns, tests, pthrs):\n",
    "    convert = f\"3dAFNItoNIFTI -prefix {nii_fn} {brik_fn}[{brik_i}]\"\n",
    "    os.system(convert)\n",
    "\n",
    "    nii_img = nib.load(nii_fn)\n",
    "    z_thresh = p_to_z(pthr)\n",
    "    info = nii_img.get_fdata()\n",
    "\n",
    "    clust_ext = cluster_df.loc[cluster_df[\"pthr\"] == pthr, alpha].values[0]\n",
    "    nii_thr_img = threshold_img(nii_img, z_thresh, cluster_threshold=clust_ext)\n",
    "\n",
    "    clusters = get_clusters_table(nii_thr_img, stat_threshold=z_thresh, two_sided=True)\n",
    "    clusters_with_regions = map_clusters_to_regions(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn.image import load_img\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "import numpy as np\n",
    "\n",
    "# Load the Juelich atlas\n",
    "juelich_atlas = datasets.fetch_atlas_juelich(\"maxprob-thr0-1mm\")\n",
    "atlas_filename = juelich_atlas.maps\n",
    "atlas_labels = juelich_atlas.labels\n",
    "\n",
    "# Load the Harvard-Oxford atlas\n",
    "harvard_oxford_atlas = datasets.fetch_atlas_harvard_oxford(\"sub-maxprob-thr25-1mm\")\n",
    "atlas_filename = harvard_oxford_atlas.maps\n",
    "atlas_labels = harvard_oxford_atlas.labels\n",
    "\n",
    "# Load the atlas image\n",
    "atlas_img = load_img(atlas_filename)\n",
    "\n",
    "\n",
    "# Function to find the region for a given coordinate\n",
    "def find_region(coord):\n",
    "    # Transform MNI coordinates to voxel indices\n",
    "    voxel_indices = np.round(\n",
    "        nib.affines.apply_affine(np.linalg.inv(atlas_img.affine), coord)\n",
    "    ).astype(int)\n",
    "    # Get the label index for the voxel\n",
    "    label_idx = atlas_img.get_fdata()[tuple(voxel_indices)]\n",
    "    region_name = (\n",
    "        atlas_labels[int(label_idx)]\n",
    "        if int(label_idx) < len(atlas_labels)\n",
    "        else \"Unknown\"\n",
    "    )\n",
    "    return region_name\n",
    "\n",
    "\n",
    "# Extract the coordinates from the clusters table and map to regions\n",
    "def map_clusters_to_regions(clusters_df):\n",
    "    coordinates = clusters_df[[\"X\", \"Y\", \"Z\"]].values\n",
    "    regions = [find_region(coord) for coord in coordinates]\n",
    "    clusters_df[\"Region\"] = regions\n",
    "    return clusters_df\n",
    "\n",
    "\n",
    "# Iterate over your clusters and map to regions\n",
    "for brik_i, nii_fn, test, pthr in zip(brik_idx, nii_fns, tests, pthrs):\n",
    "    convert = f\"3dAFNItoNIFTI -prefix {nii_fn} {brik_fn}[{brik_i}]\"\n",
    "    os.system(convert)\n",
    "\n",
    "    nii_img = nib.load(nii_fn)\n",
    "    z_thresh = p_to_z(pthr)\n",
    "    info = nii_img.get_fdata()\n",
    "\n",
    "    clust_ext = cluster_df.loc[cluster_df[\"pthr\"] == pthr, alpha].values[0]\n",
    "    nii_thr_img = threshold_img(nii_img, z_thresh, cluster_threshold=clust_ext)\n",
    "    print(clust_ext, pthr, z_thresh)\n",
    "\n",
    "    clusters = nilearn.reporting.get_clusters_table(\n",
    "        nii_thr_img, stat_threshold=z_thresh, two_sided=True\n",
    "    )\n",
    "    clusters_with_regions = map_clusters_to_regions(clusters)\n",
    "    print(clusters_with_regions)\n",
    "\n",
    "    output_filename = op.join(abide_dir, f\"clusters_with_subregions_{test}_pthr_{pthr}.csv\")\n",
    "    clusters_with_regions.to_csv(output_filename, index=False)\n",
    "    print(f\"Saved clusters with regions to {output_filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine sub-figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    output_file = op.join(fig_dir, f\"0_{test}.png\")\n",
    "    \n",
    "    figure1 = plt.figure(figsize=(10, 6))\n",
    "    gs = GridSpec(nrows=2, ncols=3, figure=figure1)\n",
    "\n",
    "    for col, data_type in enumerate([\"\", \"-cohen\"]):\n",
    "        img_files = [ \n",
    "            op.join(fig_dir, f\"{test}_volume{data_type}.png\"),\n",
    "            op.join(fig_dir, f\"{test}_surface{data_type}.png\"),\n",
    "        ]\n",
    "\n",
    "        for row, fn in enumerate(img_files):\n",
    "            img1 = mpimg.imread(fn)\n",
    "            #if row == 0:\n",
    "            #    img1 = trim_image(img=img1, tol=1, fix=True)\n",
    "\n",
    "            ax = figure1.add_subplot(gs[row, col], aspect=\"equal\")\n",
    "            ax.imshow(img1)\n",
    "\n",
    "            if col == 0 and row == 0:\n",
    "                ax.set_title(\"Z-Map\", fontsize=12)\n",
    "            if col == 1 and row == 0:\n",
    "                ax.set_title(\"Effect Size\", fontsize=12)\n",
    "            ax.set_axis_off()\n",
    "\n",
    "    dec_fn = op.join(fig_dir, f\"{test}_wordcloud.png\")\n",
    "    img1 = mpimg.imread(dec_fn)\n",
    "    ax = figure1.add_subplot(gs[0:2, 2], aspect=\"equal\")\n",
    "    ax.imshow(img1)\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    figure1.suptitle(test_dict[test], fontsize=14)\n",
    "    figure1.subplots_adjust(wspace=0.1, hspace=0.1) # top=1.2\n",
    "    figure1.savefig(output_file, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC of connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "summart_stats = pd.read_csv(op.join(\"./abide\", \"rsfc-qc.csv\"))\n",
    "summart_stats[\"Score\"] = summart_stats[\"Score\"].apply(lambda x: ast.literal_eval(x)[0] if isinstance(x, str) and x.startswith('[') else x)\n",
    "summart_stats[\"Score\"] = summart_stats[\"Score\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.strip(\n",
    "    summart_stats,\n",
    "    y=\"Score\",\n",
    "    color=\"ID\",\n",
    "    facet_col=\"Stat\",\n",
    "    stripmode=\"group\",\n",
    "    facet_col_wrap=4,\n",
    "    facet_col_spacing=0.08,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(showline=True, linewidth=2, linecolor=\"black\", mirror=True)\n",
    "fig.update_yaxes(\n",
    "    constrain=\"domain\",\n",
    "    matches=None,\n",
    "    showline=True,\n",
    "    linewidth=2,\n",
    "    linecolor=\"black\",\n",
    "    mirror=True,\n",
    "    title=None,\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=900,\n",
    "    autosize=True,\n",
    "    font_size=14,\n",
    "    plot_bgcolor=\"white\",\n",
    "    xaxis_gridcolor=\"white\",\n",
    "    yaxis_gridcolor=\"white\",\n",
    "    xaxis_gridwidth=2,\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.for_each_yaxis(lambda yaxis: yaxis.update(showticklabels=True))\n",
    "fig.write_html(op.join(fig_dir, \"summary_stats.html\"), full_html=True, include_plotlyjs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get outliers from participants.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_df = pd.read_csv(\"/Users/jperaza/Desktop/participants.tsv\", sep=\"\\t\")\n",
    "\n",
    "rater_columns = [\n",
    "    \"qc_rater_1\", \n",
    "    \"qc_anat_rater_2\", \n",
    "    \"qc_func_rater_2\",\n",
    "    \"qc_anat_rater_3\",\n",
    "    \"qc_func_rater_3\",\n",
    "]\n",
    "\n",
    "ppt_to_exclude = []\n",
    "for col in rater_columns:\n",
    "    ppt_to_exclude.extend(ppt_df[ppt_df[col] == \"fail\"][\"participant_id\"].to_list())\n",
    "\n",
    "pd.DataFrame(list(set(ppt_to_exclude))).to_csv(op.join(fig_dir, \"exclude_ppts.csv\"), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
